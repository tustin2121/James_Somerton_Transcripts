{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports for all notebooks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDDIT THINGS\n",
    "\n",
    "def scrape_reddit(the_subreddit, pages = 40):\n",
    "    all_posts = []\n",
    "    first_url = 'http://www.reddit.com/r/' + the_subreddit + '.json'\n",
    "    url = first_url\n",
    "    list_of_df = []\n",
    "    \n",
    "    # Get Sanity Check:\n",
    "    quick_check = requests.get(first_url, headers = {'User-agent':'Electronic Goddess'})\n",
    "    if int(str(quick_check)[11:14]) == 200:\n",
    "        print(\"Get request successful.\")\n",
    "        time.sleep(3)\n",
    "        print(\"Initiating Scrape...\")\n",
    "    else:\n",
    "        print(\"Get request not 200, instead recieved:\" + str(quick_check))\n",
    "        return\n",
    "    \n",
    "    # Scraping:\n",
    "    for round in range(pages):\n",
    "        try:\n",
    "            res = requests.get(url, headers = {'User-agent':'Electronic Goddess'})\n",
    "            data = res.json()    # Cut around here if we need other bits of info\n",
    "            list_of_posts = data['data']['children']\n",
    "            all_posts = all_posts + list_of_posts\n",
    "            after = data['data']['after']\n",
    "            url = first_url +'?after=' + after\n",
    "            print('Round: '+ str(round + 1))\n",
    "            time.sleep(1)        # Can be adjusted\n",
    "        except:\n",
    "            print('Limit likely hit.  Returning available posts.')\n",
    "            break\n",
    "#        return all_posts # This can be un-commented out for a straight forward raw scrape\n",
    "\n",
    "    # Formats the parts we care about into a list of dictionaries that'll become the dataframe\n",
    "    for i in range(len(all_posts)):\n",
    "        index_dictionary = {\n",
    "                'title' : all_posts[i]['data']['title'],\n",
    "                'selftext': all_posts[i]['data']['selftext'],\n",
    "                'subreddit' : all_posts[i]['data']['subreddit']\n",
    "            }\n",
    "        list_of_df.append(index_dictionary)\n",
    "    return pd.DataFrame(list_of_df, columns = ['title','selftext','subreddit'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Quality of Life Imports\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "datetime.fromtimestamp(time()).strftime('%m/%d/%Y, %H:%M:%S')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium\n",
    "# Scraping Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import re\n",
    "\n",
    "def open_browser(alt_user_name = 'Thank you for your website'):\n",
    "    path = '../Garage/chromedriver'         # Path to Chromedriver\n",
    "    return webdriver.Chrome(executable_path = path)\n",
    "\n",
    "def open_browser(alt_user_name = 'Thank you for your website'):\n",
    "    opts = Options()\n",
    "    opts.add_argument(\"user-agent=\" + str(alt_user_name))\n",
    "    path = '../Garage/chromedriver'         # Path to Chromedriver\n",
    "    return webdriver.Chrome(executable_path = path, options=opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
